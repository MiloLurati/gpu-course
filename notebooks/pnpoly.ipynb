{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point-in-Polygon\n",
    "\n",
    "The goal of this exercise is to teach you about the different memory spaces available in CUDA.\n",
    "\n",
    "To complete this exercise you need to do the following:\n",
    "\n",
    "**Step 1.** Carefully read the entire notebook before you continue, make sure you understand everything, and run all the cells once from top to bottom.\n",
    "\n",
    "**Step 2.** Change both the kernel and the Python code to store the vertices in constant memory space and only use the vertices in constant memory within the kernel.\n",
    "\n",
    "Hints: Inside the CUDA kernel declare a float2 array of size VERTICES as a global variable. Choose a unique name and use the ``__constant__`` qualifier to declare this variable as residing in constant memory space. \n",
    "Make sure the constant memory array is used correctly inside the CUDA kernel, instead of the currently used ‘vertices’ array in global memory. Just leave the original global memory array unused in the kernel (if you change the kernel arguments you have to change the hostcode as well).\n",
    "\n",
    "Hints 2: You can use memcpy_htod() to copy the data to device memory, but you need to find the symbol to copy the data to. [See PyCuda documentation on get_global](https://documen.tician.de/pycuda/driver.html#pycuda.driver.Module.get_global).\n",
    "\n",
    "As usual we start with some imports and initializing PyCuda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pycuda.driver as drv\n",
    "from pycuda.compiler import SourceModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize pycuda and create a device context\n",
    "drv.init()\n",
    "context = drv.Device(0).make_context()\n",
    "\n",
    "#get compute capability for compiling CUDA kernels\n",
    "devprops = { str(k): v for (k, v) in context.get_device().get_attributes().items() }\n",
    "cc = str(devprops['COMPUTE_CAPABILITY_MAJOR']) + str(devprops['COMPUTE_CAPABILITY_MINOR'])\n",
    "\n",
    "def allocate(n, dtype=np.float32):\n",
    "    \"\"\" allocate context-portable device mapped host memory \"\"\"\n",
    "    return drv.pagelocked_zeros(int(n), dtype, order='C', mem_flags=drv.host_alloc_flags.PORTABLE|drv.host_alloc_flags.DEVICEMAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell defines our CUDA kernel, by running the cell the contents of the cell will be written to a file named pnpoly.cu.\n",
    "\n",
    "This kernel implements the crossing number algorithm for determining whether a point resides on the inside or on the outside of a polygon in the 2D plane. The polygon is defined as a set of vertices and the points are simply x,y coordinates. The result is a bitmap that indicates for each point if it's in or out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile pnpoly.cu\n",
    "\n",
    "#define VERTICES 600\n",
    "__global__ void cn_pnpoly(int *bitmap, float2 *points, float2 *vertices, int n) {\n",
    "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    if (i < n) {\n",
    "        int c = 0;\n",
    "        float2 p = points[i];\n",
    "\n",
    "        int k = VERTICES-1;\n",
    "\n",
    "        for (int j=0; j<VERTICES; k = j++) {    // edge from vk to vj\n",
    "            float2 vj = vertices[j]; \n",
    "            float2 vk = vertices[k]; \n",
    "\n",
    "            float slope = (vk.x-vj.x) / (vk.y-vj.y);\n",
    "\n",
    "            if ( (  (vj.y>p.y) != (vk.y>p.y)) &&            //if p is between vj and vk vertically\n",
    "                    (p.x < slope * (p.y-vj.y) + vj.x) ) {   //if p.x crosses the line vk-vj when moved in positive x-direction\n",
    "                c = !c;\n",
    "            }\n",
    "        }\n",
    "\n",
    "        bitmap[i] = c; // 0 if even (out), and 1 if odd (in)\n",
    "    }\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to prepare the input and output data structures for our kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the number of points and the number of vertices\n",
    "size = np.int32(2e7)\n",
    "vertices = 600\n",
    "\n",
    "#allocate page-locked device-mapped host memory\n",
    "points = allocate(2*size, np.float32)\n",
    "bitmap = allocate(size, np.int32)\n",
    "vertices = allocate(2*vertices, np.float32)\n",
    "d_bitmap = np.intp(bitmap.base.get_device_pointer())\n",
    "d_points = np.intp(points.base.get_device_pointer())\n",
    "\n",
    "#generate/read input data\n",
    "np.copyto(points, np.random.randn(2*size).astype(np.float32))\n",
    "np.copyto(vertices, np.fromfile(\"../pnpoly/vertices.dat\", dtype=np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we setup GPU memory for the input and output data as well as the argument list and launch parameters. You may notice the points are not copied here, because we are using device-mapped host memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#allocate gpu device memory for storing the vertices\n",
    "d_vertices = drv.mem_alloc(vertices.nbytes)\n",
    "\n",
    "#copy from host memory to GPU device memory\n",
    "drv.memcpy_htod(d_vertices, vertices)\n",
    "\n",
    "#kernel arguments\n",
    "gpu_args = [d_bitmap, d_points, d_vertices, size]\n",
    "\n",
    "#setup thread block sizes\n",
    "threads = (256, 1, 1)\n",
    "grid = (int(np.ceil(size/float(threads[0]))), 1)\n",
    "\n",
    "#create events for time measurement\n",
    "start = drv.Event()\n",
    "end = drv.Event()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now before we turn to our CUDA kernel we first run a reference kernel to compute the reference output, which allows us to check if the result from our kernel is correct. **It is recommended to only run this cell once, before you make any modifications.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile and run the reference kernel\n",
    "with open('../pnpoly/pnpoly.cu', 'r') as f:\n",
    "    kernel_string = f.read()\n",
    "module = SourceModule(kernel_string, arch='compute_' + cc, code='sm_' + cc,\n",
    "                cache_dir=False, no_extern_c=True)\n",
    "#compute the reference answer using the reference kernel\n",
    "reference = allocate(size, np.int32)\n",
    "d_reference = np.intp(reference.base.get_device_pointer())\n",
    "reference_kernel = module.get_function(\"cn_pnpoly_reference_kernel\")\n",
    "ref_args = [d_reference, d_points, d_vertices, size]\n",
    "context.synchronize()\n",
    "start.record()\n",
    "reference_kernel(*ref_args, block=threads, grid=grid)\n",
    "end.record()\n",
    "context.synchronize()\n",
    "print(\"reference kernel took\", end.time_since(start), \"ms.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to compile and run our kernel and see if the result is correct. \n",
    "\n",
    "Note that this cell will print PASSED when you haven't made any modifications. The goal here is to make sure that the kernel uses the vertices from constant memory. If you re-run this cell after your modifications it should still print PASSED and hopefully it will be slightly faster, but that differs per GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read kernel into string\n",
    "with open('pnpoly.cu', 'r') as f:\n",
    "    kernel_string = f.read()\n",
    "\n",
    "#compile the kernels\n",
    "module = SourceModule(kernel_string, arch='compute_' + cc, code='sm_' + cc,\n",
    "                cache_dir=False)\n",
    "pnpoly_kernel = module.get_function(\"cn_pnpoly\")\n",
    "\n",
    "# HINT: need to reference constant memory\n",
    "# HINT: need to also copy memory to constant array\n",
    "\n",
    "#make sure all previous operations have completed\n",
    "context.synchronize()\n",
    "\n",
    "#run the kernel and measure time using events\n",
    "start.record()\n",
    "pnpoly_kernel(*gpu_args, block=threads, grid=grid)\n",
    "end.record()\n",
    "context.synchronize()\n",
    "\n",
    "print(\"cn_pnpoly took\", end.time_since(start), \"ms.\")\n",
    "\n",
    "print(\"PASSED\" if np.sum(np.absolute(bitmap - reference)) == 0 else \"FAILED\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}