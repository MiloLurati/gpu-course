{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local averages\n",
    "\n",
    "In this hands-on your task is to optimize the performance of a kernel that computes averages.\n",
    "The input is a one-dimensional array of size **N**, and the input is a different one-dimensional array of size **N/4** where each element **i** is the average of 4 consecutive elements of the input array.\n",
    "\n",
    "Do not worry if the definition at this stage is still a bit vague, the code will be soon presented and you will realize it is self explanatory.\n",
    "But first, let us start by importing the necessary Python modules, initialize the GPU, and create the necessary arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pycuda.driver as drv\n",
    "from pycuda.compiler import SourceModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize pycuda and create a device context\n",
    "drv.init()\n",
    "context = drv.Device(0).make_context()\n",
    "\n",
    "#get compute capability for compiling CUDA kernels\n",
    "devprops = { str(k): v for (k, v) in context.get_device().get_attributes().items() }\n",
    "cc = str(devprops['COMPUTE_CAPABILITY_MAJOR']) + str(devprops['COMPUTE_CAPABILITY_MINOR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = np.int32(2e30)\n",
    "A = np.random.randn(N).astype(np.float32)\n",
    "B1 = np.zeros(N/4).astype(np.float32)\n",
    "B2 = np.zeros_like(B1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the right data structures, we can write a function to compute our local averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_averages(A, B, N):\n",
    "    for i in range(0, N/4):\n",
    "        temp = 0.0\n",
    "        for j in range(0, 4):\n",
    "            temp = temp + A[(i * 4) + j]\n",
    "        B[i] = temp / 4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now execute and time our code. In this way we will save our reference output (for testing purpose) and have a glimpse at the execution time on the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "local_averages(A, B1, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is now time to introduce the naive CUDA code, and save it to a local file, as done in previous exercise. The main difference this time is that the code is already correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile local_averages.cu\n",
    "\n",
    "__global__ void local_averages_kernel(float * A, float * B, int size_B)\n",
    "{\n",
    "    int index = (blockIdx.x * blockDim.x) + threadIdx.x;\n",
    "    \n",
    "    if ( index < size_B )\n",
    "    {\n",
    "        float temp = 0.0;\n",
    "        \n",
    "        for ( int j = 0; j < 4; j++ )\n",
    "        {\n",
    "            temp = temp + A[(index * 4) + j];\n",
    "        }\n",
    "        B[index] = temp / 4.0;\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your goal at this point is to understand how this kernel works, and improve its performance. But before doing that, let us allocate memory on the GPU, and prepare the execution environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first we allocate GPU memory and copy the data to the GPU\n",
    "args = [A, B2]\n",
    "gpu_args = []\n",
    "for arg in args:\n",
    "    gpu_args.append(drv.mem_alloc(arg.nbytes))\n",
    "    drv.memcpy_htod(gpu_args[-1], arg)\n",
    "gpu_args.append(N/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup the thread block dimensions (x, y, z)\n",
    "threads = (1024, 1, 1)\n",
    "#setup the number of thread blocks in (x, y, z)\n",
    "grid = (int(np.ceil((N/4)/float(threads[0]))), 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is time to execute the naive kernel, and measure its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have to pass the source code as a string, so we first read it from disk\n",
    "with open('local_averages.cu', 'r') as f:\n",
    "    kernel_string = f.read()\n",
    "\n",
    "#compile the kernel\n",
    "vector_add = SourceModule(kernel_string, arch='compute_' + cc, code='sm_' + cc,\n",
    "                          cache_dir=False).get_function(\"local_averages_kernel\")\n",
    "\n",
    "#Make sure all previous operations on the GPU have completed\n",
    "context.synchronize()\n",
    "#Create events for measuring time\n",
    "start = drv.Event()\n",
    "end = drv.Event()\n",
    "\n",
    "#Run the kernel\n",
    "start.record()\n",
    "vector_add(*gpu_args, block=threads, grid=grid, stream=None, shared=0)\n",
    "end.record()\n",
    "\n",
    "#Wait for the kernel to finish\n",
    "context.synchronize()\n",
    "\n",
    "#Print how long it took\n",
    "print(\"local_averages_kernel took\", end.time_since(start), \"ms.\")\n",
    "\n",
    "#copy output data back from GPU\n",
    "drv.memcpy_dtoh(c, gpu_args[0])\n",
    "\n",
    "#check for correctness\n",
    "print(\"PASSED\" if np.allclose(B2, B1, atol=1e-6) else \"FAILED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is now your turn to change the CUDA code and improve the performance of the kernel.\n",
    "\n",
    "To avoid you losing track of the naive kernel's execution time, we are going to replicate the previous cell below this one. Just go back to the cell containing the CUDA code, modify the code, run that cell, and then run the one below. In the cell below we also take care to clean the output array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have to pass the source code as a string, so we first read it from disk\n",
    "with open('local_averages.cu', 'r') as f:\n",
    "    kernel_string = f.read()\n",
    "\n",
    "#compile the kernel\n",
    "vector_add = SourceModule(kernel_string, arch='compute_' + cc, code='sm_' + cc,\n",
    "                          cache_dir=False).get_function(\"local_averages_kernel\")\n",
    "\n",
    "#make sure the output data is clean\n",
    "B2 = np.zeros_like(B1)\n",
    "drv.memcpy_htod(gpu_args[1], B2)\n",
    "\n",
    "#Make sure all previous operations on the GPU have completed\n",
    "context.synchronize()\n",
    "#Create events for measuring time\n",
    "start = drv.Event()\n",
    "end = drv.Event()\n",
    "\n",
    "#Run the kernel\n",
    "start.record()\n",
    "vector_add(*gpu_args, block=threads, grid=grid, stream=None, shared=0)\n",
    "end.record()\n",
    "\n",
    "#Wait for the kernel to finish\n",
    "context.synchronize()\n",
    "\n",
    "#Print how long it took\n",
    "print(\"local_averages_kernel took\", end.time_since(start), \"ms.\")\n",
    "\n",
    "#copy output data back from GPU\n",
    "drv.memcpy_dtoh(c, gpu_args[0])\n",
    "\n",
    "#check for correctness\n",
    "print(\"PASSED\" if np.allclose(B2, B1, atol=1e-6) else \"FAILED\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
